{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Demo (structuring)\n",
    "\n",
    "Injection of first order logic rules into a neural network for iris classification task via structuring.\n",
    "\n",
    "Some imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "from psyki import KnowledgeModule\n",
    "from psyki.fol import Parser\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from test import get_mlp\n",
    "from test import get_rules\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.python.keras.layers import Dense, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Loading iris dataset and separation into train and test set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n3                  4.6               3.1                1.5               0.2   \n149                5.9               3.0                5.1               1.8   \n98                 5.1               2.5                3.0               1.1   \n6                  4.6               3.4                1.4               0.3   \n68                 6.2               2.2                4.5               1.5   \n..                 ...               ...                ...               ...   \n9                  4.9               3.1                1.5               0.1   \n103                6.3               2.9                5.6               1.8   \n67                 5.8               2.7                4.1               1.0   \n117                7.7               3.8                6.7               2.2   \n47                 4.6               3.2                1.4               0.2   \n\n     target  \n3         0  \n149       2  \n98        1  \n6         0  \n68        1  \n..      ...  \n9         0  \n103       2  \n67        1  \n117       2  \n47        0  \n\n[75 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal length (cm)</th>\n      <th>sepal width (cm)</th>\n      <th>petal length (cm)</th>\n      <th>petal width (cm)</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>149</th>\n      <td>5.9</td>\n      <td>3.0</td>\n      <td>5.1</td>\n      <td>1.8</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>5.1</td>\n      <td>2.5</td>\n      <td>3.0</td>\n      <td>1.1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>4.6</td>\n      <td>3.4</td>\n      <td>1.4</td>\n      <td>0.3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>6.2</td>\n      <td>2.2</td>\n      <td>4.5</td>\n      <td>1.5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>4.9</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>103</th>\n      <td>6.3</td>\n      <td>2.9</td>\n      <td>5.6</td>\n      <td>1.8</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>5.8</td>\n      <td>2.7</td>\n      <td>4.1</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>117</th>\n      <td>7.7</td>\n      <td>3.8</td>\n      <td>6.7</td>\n      <td>2.2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>4.6</td>\n      <td>3.2</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>75 rows Ã— 5 columns</p>\n</div>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = load_iris(return_X_y=True, as_frame=True)\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "encoder.fit_transform([y])\n",
    "dataset = x.join(y)\n",
    "\n",
    "train, test = train_test_split(dataset, test_size=0.5, random_state=0)\n",
    "train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import FOL rules:\n",
    "\n",
    "- PL <= 2.28 <- X = setosa\n",
    "- PL > 2.28 ^ PW > 1.64 <- X = virginica\n",
    "- PL > 2.28 ^ PW <= 1.64 <- X = versicolor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "features_mapping = {\n",
    "    'SL': 0,\n",
    "    'SW': 1,\n",
    "    'PL': 2,\n",
    "    'PW': 3,\n",
    "}\n",
    "class_mapping = {\n",
    "    'setosa': tf.constant([1, 0, 0], dtype=tf.float32),\n",
    "    'virginica': tf.constant([0, 1, 0], dtype=tf.float32),\n",
    "    'versicolor': tf.constant([0, 0, 1], dtype=tf.float32)\n",
    "}\n",
    "\n",
    "parser = Parser.default_parser()\n",
    "iris_rules = get_rules('iris')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Injection of fuzzy logic function derived from FOL rules into a neural network."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_44 (Lambda)              (None, 1)            0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_106 (Dense)               (None, 1)            5           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_36 (Lambda)              (None, 1)            0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_88 (Dense)                (None, 1)            5           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_39 (Lambda)              (None, 1)            0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_95 (Dense)                (None, 1)            5           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_40 (Lambda)              (None, 1)            0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_97 (Dense)                (None, 1)            5           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_43 (Lambda)              (None, 1)            0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_104 (Dense)               (None, 1)            5           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_58 (Concatenate)    (None, 2)            0           lambda_44[0][0]                  \n",
      "                                                                 dense_106[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "L_1 (Dense)                     (None, 16)           80          Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_48 (Concatenate)    (None, 2)            0           lambda_36[0][0]                  \n",
      "                                                                 dense_88[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_52 (Concatenate)    (None, 2)            0           lambda_39[0][0]                  \n",
      "                                                                 dense_95[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_53 (Concatenate)    (None, 2)            0           lambda_40[0][0]                  \n",
      "                                                                 dense_97[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_57 (Concatenate)    (None, 2)            0           lambda_43[0][0]                  \n",
      "                                                                 dense_104[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_107 (Dense)               (None, 1)            3           concatenate_58[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_108 (Dense)               (None, 1)            3           concatenate_58[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "L_2 (Dense)                     (None, 16)           272         L_1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_89 (Dense)                (None, 1)            3           concatenate_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_90 (Dense)                (None, 1)            3           concatenate_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_96 (Dense)                (None, 1)            3           concatenate_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_98 (Dense)                (None, 1)            3           concatenate_53[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_105 (Dense)               (None, 1)            3           concatenate_57[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "maximum_14 (Maximum)            (None, 1)            0           dense_107[0][0]                  \n",
      "                                                                 dense_108[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "L_3 (Dense)                     (None, 3)            51          L_2[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "maximum_12 (Maximum)            (None, 1)            0           dense_89[0][0]                   \n",
      "                                                                 dense_90[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "minimum_8 (Minimum)             (None, 1)            0           dense_96[0][0]                   \n",
      "                                                                 dense_98[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "minimum_9 (Minimum)             (None, 1)            0           dense_105[0][0]                  \n",
      "                                                                 maximum_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_59 (Concatenate)    (None, 6)            0           L_3[0][0]                        \n",
      "                                                                 maximum_12[0][0]                 \n",
      "                                                                 minimum_8[0][0]                  \n",
      "                                                                 minimum_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_109 (Dense)               (None, 10)           70          concatenate_59[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 519\n",
      "Trainable params: 473\n",
      "Non-trainable params: 46\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_features = Input((4,), name='Input')\n",
    "network = get_mlp(input=input_features, output=3, layers=3, neurons=16, activation_function='relu',\n",
    "                  last_activation_function='softmax')\n",
    "kns = KnowledgeModule.modules(iris_rules, parser, input_features, features_mapping)\n",
    "model = Model(input_features, network).layers[-1].output\n",
    "output = Dense(10, activation='softmax')((Concatenate(axis=1)([model] + kns)))\n",
    "model = Model(input_features, output)\n",
    "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "15/15 [==============================] - 0s 468us/step - loss: 2.2717 - accuracy: 0.0667\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 612us/step - loss: 2.2004 - accuracy: 0.0800\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 496us/step - loss: 2.1278 - accuracy: 0.0800\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 489us/step - loss: 2.0484 - accuracy: 0.0800\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 500us/step - loss: 1.9530 - accuracy: 0.0800\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 511us/step - loss: 1.8587 - accuracy: 0.1467\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 417us/step - loss: 1.7794 - accuracy: 0.4400\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 482us/step - loss: 1.7119 - accuracy: 0.4667\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 376us/step - loss: 1.6511 - accuracy: 0.4667\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 464us/step - loss: 1.5969 - accuracy: 0.4667\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 337us/step - loss: 1.5474 - accuracy: 0.4800\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 416us/step - loss: 1.5016 - accuracy: 0.5067\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 401us/step - loss: 1.4562 - accuracy: 0.5600\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 469us/step - loss: 1.4140 - accuracy: 0.6267\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 407us/step - loss: 1.3734 - accuracy: 0.6533\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 360us/step - loss: 1.3341 - accuracy: 0.7200\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 456us/step - loss: 1.2970 - accuracy: 0.8000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 326us/step - loss: 1.2608 - accuracy: 0.8267\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 366us/step - loss: 1.2254 - accuracy: 0.8800\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 405us/step - loss: 1.1921 - accuracy: 0.8933\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 339us/step - loss: 1.1586 - accuracy: 0.9200\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 437us/step - loss: 1.1275 - accuracy: 0.9467\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 375us/step - loss: 1.0965 - accuracy: 0.9467\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 398us/step - loss: 1.0671 - accuracy: 0.9467\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 404us/step - loss: 1.0382 - accuracy: 0.9200\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 347us/step - loss: 1.0105 - accuracy: 0.9467\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 406us/step - loss: 0.9853 - accuracy: 0.9200\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 327us/step - loss: 0.9554 - accuracy: 0.9467\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 401us/step - loss: 0.9311 - accuracy: 0.9467\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 512us/step - loss: 0.9058 - accuracy: 0.9467\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 354us/step - loss: 0.8810 - accuracy: 0.9467\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 425us/step - loss: 0.8601 - accuracy: 0.9467\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 332us/step - loss: 0.8368 - accuracy: 0.9467\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 379us/step - loss: 0.8149 - accuracy: 0.9467\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 377us/step - loss: 0.7916 - accuracy: 0.9467\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 334us/step - loss: 0.7714 - accuracy: 0.9467\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 394us/step - loss: 0.7522 - accuracy: 0.9467\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 335us/step - loss: 0.7320 - accuracy: 0.9467\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 339us/step - loss: 0.7125 - accuracy: 0.9467\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 418us/step - loss: 0.6943 - accuracy: 0.9467\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 352us/step - loss: 0.6776 - accuracy: 0.9467\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 386us/step - loss: 0.6610 - accuracy: 0.9600\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 387us/step - loss: 0.6457 - accuracy: 0.9467\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 343us/step - loss: 0.6293 - accuracy: 0.9600\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 396us/step - loss: 0.6138 - accuracy: 0.9467\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 339us/step - loss: 0.5974 - accuracy: 0.9600\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 370us/step - loss: 0.5836 - accuracy: 0.9733\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 415us/step - loss: 0.5708 - accuracy: 0.9733\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 329us/step - loss: 0.5571 - accuracy: 0.9600\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 406us/step - loss: 0.5456 - accuracy: 0.9600\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x15371ae20>"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x, train_y = train.iloc[:,:-1], train.iloc[:,-1]\n",
    "model.fit(train_x, train_y, verbose=1, batch_size=5, epochs=50)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Evaluation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x154451940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 714us/step - loss: 0.5706 - accuracy: 0.9867\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.5706334710121155, 0.9866666793823242]"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x, test_y = test.iloc[:,:-1], test.iloc[:,-1]\n",
    "model.evaluate(test_x, test_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Demo ends here\n",
    "If you are reading it from `https://anonymous.4open.science/` there is a chance that the demo is duplicated.\n",
    "Just ignore the following text."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}